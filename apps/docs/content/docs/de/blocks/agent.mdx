---
title: Agent
---

import { Callout } from 'fumadocs-ui/components/callout'
import { Step, Steps } from 'fumadocs-ui/components/steps'
import { Tab, Tabs } from 'fumadocs-ui/components/tabs'
import { Image } from '@/components/ui/image'
import { Video } from '@/components/ui/video'

Der Agent-Block dient als Schnittstelle zwischen Ihrem Workflow und Large Language Models (LLMs). Er führt Inferenzanfragen an verschiedene KI-Anbieter aus, verarbeitet natürlichsprachliche Eingaben gemäß definierten Anweisungen und erzeugt strukturierte oder unstrukturierte Ausgaben für die nachgelagerte Verarbeitung.

<div className="flex justify-center">
  <Image
    src="/static/blocks/agent.png"
    alt="Agent-Block-Konfiguration"
    width={500}
    height={400}
    className="my-6"
  />
</div>

## Überblick

Der Agent-Block ermöglicht Ihnen:

<Steps>
  <Step>
    <strong>Natürliche Sprache verarbeiten</strong>: Benutzereingaben analysieren und kontextbezogene Antworten generieren
  </Step>
  <Step>
    <strong>KI-gestützte Aufgaben ausführen</strong>: Inhaltsanalyse, -erstellung und Entscheidungsfindung durchführen
  </Step>
  <Step>
    <strong>Externe Tools aufrufen</strong>: Während der Verarbeitung auf APIs, Datenbanken und Dienste zugreifen
  </Step>
  <Step>
    <strong>Strukturierte Ausgabe erzeugen</strong>: JSON-Daten zurückgeben, die Ihren Schema-Anforderungen entsprechen
  </Step>
</Steps> 

## Konfigurationsoptionen

### System-Prompt

Der System-Prompt legt die Betriebsparameter und Verhaltenseinschränkungen des Agenten fest. Diese Konfiguration definiert die Rolle des Agenten, die Antwortmethodik und die Verarbeitungsgrenzen für alle eingehenden Anfragen.

```markdown
You are a helpful assistant that specializes in financial analysis.
Always provide clear explanations and cite sources when possible.
When responding to questions about investments, include risk disclaimers.
```

### Benutzer-Prompt

Der Benutzer-Prompt stellt die primären Eingabedaten für die Inferenzverarbeitung dar. Dieser Parameter akzeptiert natürlichsprachlichen Text oder strukturierte Daten, die der Agent analysieren und auf die er reagieren wird. Zu den Eingabequellen gehören:

- **Statische Konfiguration**: Direkte Texteingabe, die in der Block-Konfiguration angegeben ist
- **Dynamische Eingabe**: Daten, die von vorgelagerten Blöcken über Verbindungsschnittstellen übergeben werden
- **Laufzeitgenerierung**: Programmatisch erzeugte Inhalte während der Workflow-Ausführung

### Modellauswahl

Der Agent-Block unterstützt mehrere LLM-Anbieter über eine einheitliche Inferenzschnittstelle. Verfügbare Modelle umfassen:

**OpenAI-Modelle**: GPT-5, GPT-4o, o1, o3, o4-mini, gpt-4.1 (API-basierte Inferenz)
**Anthropic-Modelle**: Claude 3.7 Sonnet (API-basierte Inferenz)
**Google-Modelle**: Gemini 2.5 Pro, Gemini 2.0 Flash (API-basierte Inferenz)
**Alternative Anbieter**: Groq, Cerebras, xAI, DeepSeek (API-basierte Inferenz)
**Lokale Bereitstellung**: Ollama-kompatible Modelle (selbst gehostete Inferenz)

<div className="mx-auto w-3/5 overflow-hidden rounded-lg">
  <Video src="models.mp4" width={500} height={350} />
</div>

### Temperatur

Steuern Sie die Kreativität und Zufälligkeit der Antworten:

<Tabs items={['Niedrig (0-0,3)', 'Mittel (0,3-0,7)', 'Hoch (0,7-2,0)']}>
  <Tab>
    Deterministische, fokussierte Antworten. Am besten für faktische Aufgaben, Kundensupport und
    Situationen, in denen Genauigkeit entscheidend ist.
  </Tab>
  <Tab>
    Ausgewogene Kreativität und Fokus. Geeignet für allgemeine Anwendungen, die sowohl
    Genauigkeit als auch etwas Kreativität erfordern.
  </Tab>
  <Tab>
    Kreativere, abwechslungsreichere Antworten. Ideal für kreatives Schreiben, Brainstorming und das Generieren
    vielfältiger Ideen.
  </Tab>
</Tabs>

<div className="mt-4 text-sm text-gray-600 dark:text-gray-400">
  Der Temperaturbereich (0-1 oder 0-2) variiert je nach ausgewähltem Modell.
</div>

### API-Schlüssel

Ihr API-Schlüssel für den ausgewählten LLM-Anbieter. Dieser wird sicher gespeichert und für die Authentifizierung verwendet.

### Tools

Tools erweitern die Fähigkeiten des Agenten durch externe API-Integrationen und Service-Verbindungen. Das Tool-System ermöglicht Funktionsaufrufe, sodass der Agent Operationen über die Texterstellung hinaus ausführen kann.

**Tool-Integrationsprozess**:
1. Zugriff auf den Tools-Konfigurationsbereich innerhalb des Agent-Blocks
2. Auswahl aus über 60 vorgefertigten Integrationen oder Definition benutzerdefinierter Funktionen
3. Konfiguration von Authentifizierungsparametern und Betriebseinschränkungen

<div className="mx-auto w-3/5 overflow-hidden rounded-lg">
  <Video src="tools.mp4" width={500} height={350} />
</div>

**Verfügbare Tool-Kategorien**:
- **Kommunikation**: Gmail, Slack, Telegram, WhatsApp, Microsoft Teams
- **Datenquellen**: Notion, Google Sheets, Airtable, Supabase, Pinecone
- **Webdienste**: Firecrawl, Google Search, Exa AI, Browser-Automatisierung
- **Entwicklung**: GitHub, Jira, Linear Repository- und Issue-Management
- **KI-Dienste**: OpenAI, Perplexity, Hugging Face, ElevenLabs

**Steuerung der Tool-Ausführung**:
- **Auto**: Modell bestimmt Tool-Aufruf basierend auf Kontext und Notwendigkeit
- **Required**: Tool muss bei jeder Inferenzanfrage aufgerufen werden
- **None**: Tool-Definition verfügbar, aber vom Modellkontext ausgeschlossen

<div className="mx-auto w-3/5 overflow-hidden rounded-lg">
  <Video src="granular-tool-control.mp4" width={500} height={350} />
</div>

### Antwortformat

Der Parameter für das Antwortformat erzwingt eine strukturierte Ausgabegenerierung durch JSON-Schema-Validierung. Dies gewährleistet konsistente, maschinenlesbare Antworten, die vordefinierten Datenstrukturen entsprechen:

```json
{
  "name": "user_analysis",
  "schema": {
    "type": "object",
    "properties": {
      "sentiment": {
        "type": "string",
        "enum": ["positive", "negative", "neutral"]
      },
      "confidence": {
        "type": "number",
        "minimum": 0,
        "maximum": 1
      }
    },
    "required": ["sentiment", "confidence"]
  }
}
```

Diese Konfiguration beschränkt die Ausgabe des Modells auf die Einhaltung des angegebenen Schemas, verhindert Freitext-Antworten und stellt eine strukturierte Datengenerierung sicher.

### Zugriff auf Ergebnisse

Nach Abschluss eines Agenten können Sie auf seine Ausgaben zugreifen:

- **`<agent.content>`**: Der Antworttext oder die strukturierten Daten des Agenten
- **`<agent.tokens>`**: Token-Nutzungsstatistiken (Prompt, Completion, Gesamt)
- **`<agent.tool_calls>`**: Details zu allen Tools, die der Agent während der Ausführung verwendet hat
- **`<agent.cost>`**: Geschätzte Kosten des API-Aufrufs (falls verfügbar)

## Erweiterte Funktionen

### Memory + Agent: Gesprächsverlauf

Verwenden Sie einen `Memory`Block mit einer konsistenten `id` (zum Beispiel `chat`), um Nachrichten zwischen Durchläufen zu speichern und diesen Verlauf in den Prompt des Agenten einzubeziehen.

- Fügen Sie die Nachricht des Benutzers vor dem Agenten hinzu
- Lesen Sie den Gesprächsverlauf für den Kontext
- Hängen Sie die Antwort des Agenten nach dessen Ausführung an

```yaml
# 1) Add latest user message
- Memory (operation: add)
  id: chat
  role: user
  content: {{input}}

# 2) Load conversation history
- Memory (operation: get)
  id: chat

# 3) Run the agent with prior messages available
- Agent
  System Prompt: ...
  User Prompt: |
    Use the conversation so far:
    {{memory_get.memories}}
    Current user message: {{input}}

# 4) Store the agent reply
- Memory (operation: add)
  id: chat
  role: assistant
  content: {{agent.content}}
```

Siehe die `Memory`Block-Referenz für Details: [/tools/memory](/tools/memory).

## Eingaben und Ausgaben

<Tabs items={['Configuration', 'Variables', 'Results']}>
  <Tab>
    <ul className="list-disc space-y-2 pl-6">
      <li>
        <strong>System Prompt</strong>: Anweisungen, die das Verhalten und die Rolle des Agenten definieren
      </li>
      <li>
        <strong>User Prompt</strong>: Eingabetext oder -daten zur Verarbeitung
      </li>
      <li>
        <strong>Model</strong>: KI-Modellauswahl (OpenAI, Anthropic, Google, etc.)
      </li>
      <li>
        <strong>Temperature</strong>: Steuerung der Antwort-Zufälligkeit (0-2)
      </li>
      <li>
        <strong>Tools</strong>: Array verfügbarer Tools für Funktionsaufrufe
      </li>
      <li>
        <strong>Response Format</strong>: JSON-Schema für strukturierte Ausgabe
      </li>
    </ul>
  </Tab>
  <Tab>
    <ul className="list-disc space-y-2 pl-6">
      <li>
        <strong>agent.content</strong>: Antworttext oder strukturierte Daten des Agenten
      </li>
      <li>
        <strong>agent.tokens</strong>: Token-Nutzungsstatistik-Objekt
      </li>
      <li>
        <strong>agent.tool_calls</strong>: Array mit Details zur Tool-Ausführung
      </li>
      <li>
        <strong>agent.cost</strong>: Geschätzte API-Aufrufkosten (falls verfügbar)
      </li>
    </ul>
  </Tab>
  <Tab>
    <ul className="list-disc space-y-2 pl-6">
      <li>
        <strong>Content</strong>: Primäre Antwortausgabe vom Agenten
      </li>
      <li>
        <strong>Metadata</strong>: Nutzungsstatistiken und Ausführungsdetails
      </li>
      <li>
        <strong>Access</strong>: Verfügbar in Blöcken nach dem Agenten
      </li>
    </ul>
  </Tab>
</Tabs>

## Beispielanwendungsfälle

### Automatisierung des Kundendienstes

<div className="mb-4 rounded-md border p-4">
  <h4 className="font-medium">Szenario: Bearbeitung von Kundenanfragen mit Datenbankzugriff</h4>
  <ol className="list-decimal pl-5 text-sm">
    <li>Benutzer reicht ein Support-Ticket über den API-Block ein</li>
    <li>Agent prüft Bestellungen/Abonnements in Postgres und durchsucht die Wissensdatenbank nach Anleitungen</li>
    <li>Falls eine Eskalation erforderlich ist, erstellt der Agent ein Linear-Ticket mit relevantem Kontext</li>
    <li>Agent verfasst eine klare E-Mail-Antwort</li>
    <li>Gmail sendet die Antwort an den Kunden</li>
    <li>Konversation wird im Speicher gesichert, um den Verlauf für zukünftige Nachrichten zu erhalten</li>
  </ol>
</div>

### Multi-Modell-Inhaltsanalyse

<div className="mb-4 rounded-md border p-4">
  <h4 className="font-medium">Szenario: Analyse von Inhalten mit verschiedenen KI-Modellen</h4>
  <ol className="list-decimal pl-5 text-sm">
    <li>Funktionsblock verarbeitet hochgeladenes Dokument</li>
    <li>Agent mit GPT-4o führt technische Analyse durch</li>
    <li>Agent mit Claude analysiert Stimmung und Tonfall</li>
    <li>Funktionsblock kombiniert Ergebnisse für den Abschlussbericht</li>
  </ol>
</div>

### Werkzeuggestützter Rechercheassistent

<div className="mb-4 rounded-md border p-4">
  <h4 className="font-medium">Szenario: Rechercheassistent mit Websuche und Dokumentenzugriff</h4>
  <ol className="list-decimal pl-5 text-sm">
    <li>Benutzeranfrage über Eingabe erhalten</li>
    <li>Agent durchsucht das Web mit dem Google Search-Tool</li>
    <li>Agent greift auf Notion-Datenbank für interne Dokumente zu</li>
    <li>Agent erstellt umfassenden Recherchebericht</li>
  </ol>
</div>

## Best Practices

- **Sei spezifisch in System-Prompts**: Definiere die Rolle, den Tonfall und die Einschränkungen des Agenten klar. Je spezifischer deine Anweisungen sind, desto besser kann der Agent seinen vorgesehenen Zweck erfüllen.
- **Wähle die richtige Temperatureinstellung**: Verwende niedrigere Temperatureinstellungen (0-0,3), wenn Genauigkeit wichtig ist, oder erhöhe die Temperatur (0,7-2,0) für kreativere oder abwechslungsreichere Antworten
- **Nutze Tools effektiv**: Integriere Tools, die den Zweck des Agenten ergänzen und seine Fähigkeiten erweitern. Sei selektiv bei der Auswahl der Tools, um den Agenten nicht zu überfordern. Für Aufgaben mit wenig Überschneidung verwende einen anderen Agent-Block für die besten Ergebnisse.

---
title: Agent
description: Create powerful AI agents using any LLM provider
---

import { Callout } from 'fumadocs-ui/components/callout'
import { Step, Steps } from 'fumadocs-ui/components/steps'
import { Tab, Tabs } from 'fumadocs-ui/components/tabs'
import { ThemeImage } from '@/components/ui/theme-image'

The Agent block serves as the interface between your workflow and Large Language Models (LLMs). It executes inference requests against various AI providers, processes natural language inputs according to defined instructions, and generates structured or unstructured outputs for downstream consumption.

<ThemeImage
  lightSrc="/static/light/agent-light.png"
  darkSrc="/static/dark/agent-dark.png"
  alt="Agent Block Configuration"
  width={350}
  height={175}
/>

## Capabilities

The Agent block provides the following functionality:

### Natural Language Processing
Processes unstructured text input through transformer-based neural networks, enabling semantic understanding and context-aware response generation.

### Instruction Following
Executes tasks based on system-level prompts that define behavioral parameters, response constraints, and operational guidelines.

### Tool Integration
Invokes external APIs and services through a unified function-calling interface, enabling access to real-time data and external system operations.

### Structured Output Generation
Produces responses conforming to predefined JSON Schema specifications, ensuring consistent data formats for programmatic consumption.

### Context Management
Maintains conversational state and memory across multiple interactions within a single workflow execution cycle. 

## Configuration Options

### System Prompt

The system prompt establishes the agent's operational parameters and behavioral constraints. This configuration defines the agent's role, response methodology, and processing boundaries for all incoming requests.

```markdown
You are a helpful assistant that specializes in financial analysis.
Always provide clear explanations and cite sources when possible.
When responding to questions about investments, include risk disclaimers.
```

### User Prompt

The user prompt represents the primary input data for inference processing. This parameter accepts natural language text or structured data that the agent will analyze and respond to. Input sources include:

- **Static Configuration**: Direct text input specified in the block configuration
- **Dynamic Input**: Data passed from upstream blocks through connection interfaces
- **Runtime Generation**: Programmatically generated content during workflow execution

### Model Selection

The Agent block supports multiple LLM providers through a unified inference interface. Available models include:

**OpenAI Models**: GPT-4o, o1, o3, o4-mini, gpt-4.1 (API-based inference)
**Anthropic Models**: Claude 3.7 Sonnet (API-based inference)
**Google Models**: Gemini 2.5 Pro, Gemini 2.0 Flash (API-based inference)
**Alternative Providers**: Groq, Cerebras, xAI, DeepSeek (API-based inference)
**Local Deployment**: Ollama-compatible models (self-hosted inference)

<div className="mx-auto w-3/5 overflow-hidden rounded-lg">
  <video autoPlay loop muted playsInline className="w-full -mb-2 rounded-lg" src="/models.mp4"></video>
</div>

### Temperature

Control the creativity and randomness of responses:

<Tabs items={['Low (0-0.3)', 'Medium (0.3-0.7)', 'High (0.7-2.0)']}>
  <Tab>
    More deterministic, focused responses. Best for factual tasks, customer support, and
    situations where accuracy is critical.
  </Tab>
  <Tab>
    Balanced creativity and focus. Suitable for general purpose applications that require both
    accuracy and some creativity.
  </Tab>
  <Tab>
    More creative, varied responses. Ideal for creative writing, brainstorming, and generating
    diverse ideas.
  </Tab>
</Tabs>

<p className="mt-4 text-sm text-gray-600 dark:text-gray-400">
  The temperature range (0-1 or 0-2) varies depending on the selected model.
</p>

### API Key

Your API key for the selected LLM provider. This is securely stored and used for authentication.

### Tools

Tools extend the agent's capabilities through external API integrations and service connections. The tool system enables function calling, allowing the agent to execute operations beyond text generation.

**Tool Integration Process**:
1. Access the Tools configuration section within the Agent block
2. Select from 60+ pre-built integrations or define custom functions
3. Configure authentication parameters and operational constraints

<div className="mx-auto w-3/5 overflow-hidden rounded-lg">
  <video autoPlay loop muted playsInline className="w-full -mb-2 rounded-lg" src="/tools.mp4"></video>
</div>

**Available Tool Categories**:
- **Communication**: Gmail, Slack, Telegram, WhatsApp, Microsoft Teams
- **Data Sources**: Notion, Google Sheets, Airtable, Supabase, Pinecone
- **Web Services**: Firecrawl, Google Search, Exa AI, browser automation
- **Development**: GitHub, Jira, Linear repository and issue management
- **AI Services**: OpenAI, Perplexity, Hugging Face, ElevenLabs

**Tool Execution Control**:
- **Auto**: Model determines tool invocation based on context and necessity
- **Required**: Tool must be called during every inference request
- **None**: Tool definition available but excluded from model context

<div className="mx-auto w-3/5 overflow-hidden rounded-lg">
  <video autoPlay loop muted playsInline className="w-full -mb-2 rounded-lg" src="/granular-tool-control.mp4"></video>
</div>

### Response Format

The Response Format parameter enforces structured output generation through JSON Schema validation. This ensures consistent, machine-readable responses that conform to predefined data structures:

```json
{
  "name": "user_analysis",
  "schema": {
    "type": "object",
    "properties": {
      "sentiment": {
        "type": "string",
        "enum": ["positive", "negative", "neutral"]
      },
      "confidence": {
        "type": "number",
        "minimum": 0,
        "maximum": 1
      }
    },
    "required": ["sentiment", "confidence"]
  }
}
```

This configuration constrains the model's output to comply with the specified schema, preventing free-form text responses and ensuring structured data generation.

## Inputs and Outputs

**Inputs**:
- **System Prompt**: Instructions that define the agent's behavior and role
- **User Prompt**: The actual input or question from the user
- **Memories**: Optional memory context from previous interactions
- **Model**: Which AI model to use (OpenAI, Anthropic, Google, etc.)
- **Temperature**: Controls randomness vs. consistency (0-2 depending on model)
- **API Key**: Authentication for the selected model provider
- **Tools**: Array of tools the agent can use
- **Response Format**: JSON Schema for structured output

**Outputs**:
- **Content**: The agent's response text or structured data
- **Model**: Which model was actually used
- **Tokens**: Token usage stats (prompt tokens, completion tokens, total)
- **Tool Calls**: Details of any tools the agent used
- **Cost**: Estimated cost of the API call (if available)

## Example Usage

Here's an example of how an Agent block might be configured for a customer support workflow:

```yaml
# Example Agent Configuration
systemPrompt: |
  You are a customer support agent for TechCorp.
  Always maintain a professional, friendly tone.
  If you don't know an answer, direct the customer to email support@techcorp.com.
  Never make up information about products or policies.

model: OpenAI/gpt-4
temperature: 0.2
tools:
  - ProductDatabase
  - OrderHistory
  - SupportTicketCreator
```

## Best Practices

- **Be specific in system prompts**: Clearly define the agent's role, tone, and limitations. The more specific your instructions are, the better the agent will be able to fulfill its intended purpose.
- **Choose the right temperature setting**: Use lower temperature settings (0-0.3) when accuracy is important, or increase temperature (0.7-2.0) for more creative or varied responses
- **Combine with Evaluator blocks**: Use Evaluator blocks to assess agent responses and ensure quality. This allows you to create feedback loops and implement quality control measures.
- **Leverage tools effectively**: Integrate tools that complement the agent's purpose and enhance its capabilities. Be selective about which tools you provide to avoid overwhelming the agent.

---
title: evaluation_response
description: Evaluate content
---

import { BlockInfoCard } from "@/components/block-info-card";

# evaluation_response

<BlockInfoCard 
  type="number"
  color="#4D5FFF"
  category="tools"
/>

<div className="not-prose my-6 flex justify-center"><svg
      {...props}
      width="24"
      height="22"
      viewBox="0 0 24 22"
      fill="none"
      xmlns="http://www.w3.org/2000/svg"
    >
      <path
        d="M14.4 0C14.9139 0 15.4067 0.2107 15.7678 0.5858C16.1289 0.9609 16.3334 1.4696 16.3334 2V6.5H21.6C22.1139 6.5 22.6067 6.7107 22.9678 7.0858C23.3289 7.4609 23.5334 7.9696 23.5334 8.5V19.2C23.5334 19.7304 23.3289 20.2391 22.9678 20.6142C22.6067 20.9893 22.1139 21.2 21.6 21.2H2.4C1.8861 21.2 1.3933 20.9893 1.0322 20.6142C0.6711 20.2391 0.4666 19.7304 0.4666 19.2V12C0.4666 11.4696 0.6711 10.9609 1.0322 10.5858C1.3933 10.2107 1.8861 10 2.4 10H7.6666V2C7.6666 1.4696 7.8711 0.9609 8.2322 0.5858C8.5933 0.2107 9.0861 0 9.6 0H14.4ZM14.4 2.4H9.6V19.2H14.4V2.4ZM21.6 8.9H16.3334V19.2H21.6V8.9ZM7.6666 12.5H2.4V19.2H7.6666V12.5Z"
        fill="currentColor"
      />
    </svg></div>

Assess content quality using customizable evaluation metrics and scoring criteria. Create objective evaluation frameworks with numeric scoring to measure performance across multiple dimensions.

## Tools Used

- `openai_chat`
- `anthropic_chat`
- `google_chat`
- `xai_chat`
- `deepseek_chat`
- `deepseek_reasoner`

## Configuration

### Input Parameters

| Parameter | Type | Required | Description | Default/Placeholder |
| --------- | ---- | -------- | ----------- | ------------------ |
| `metrics` | string | No | Evaluation Metrics |  |
| `schema` | string | No |  |  |
| `properties` | string | No |  |  |



## Outputs

This block does not produce any outputs.

## Example Usage

```typescript
// Example of using the evaluation_response block
{
  type: "number",
  metrics: "example",
  schema: "example",
  properties: "example"
}
```

## Notes

- Category: `tools`
- Type: `number`
